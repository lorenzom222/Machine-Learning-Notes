## Gaussian Mixture
- Assumpution that are data is generated by a mixture (combination of probabilty distrubtions) of several Gaussian (or normal) distrubtions

Observed data likelihood function:
- Gaussian Mixture Distrubtion (linear superpostion of Gaussians)

$p(x)$ = sum of normal distrubutions times weight coefficient($\pi_k$)

Constraints:
- $0 \leq \pi_k \geq 1$

- sum of weight coeff for all clusters ($K$) = 1


### Properties

$\boldsymbol{z}$: Binary vector with $K$ elements, where each element can be either 0 or 1.
- 1-of-K representation, if an element ($z_k$) of $\boldsymbol{z}$ is 1 then it belongs to the k-th cluster.
- This act somewhat like a key to the ideal solution.
- We want to achieve a $\boldsymbol{z}$ what maximizes the likelihood.

$z_k$ (binary indicator): latent variable (a variable that is not directly observed) that determines whether a point $x$ was generated by a Gaussian component or not. In other word, whether it reside in a Gaussian component or not. 
- ($z_{k} âˆˆ {0,1}$)


$K$ Gaussian component: One component is a Gaussian distrubtion that make up the mixture model. Similar to Clusters.


### Graphical Model
- Marginal-distrubution: $p(\boldsymbol{z})$
- Conditional-distrubution: $p(\boldsymbol{x}|\boldsymbol{z})$

- Joint-distrubution: $p(\boldsymbol{x}, \boldsymbol{z}) = p(\boldsymbol{z})p(\boldsymbol{x}|\boldsymbol{z})$

Z ---> X



## EM Algorithm

Expectation: Q($\theta$, $\theta^{old}$) = sum for all **Z** of the product of p(**Z**, **X**, $\theta^{old}$) and the natrual log of p(**Z**, **X**, $\theta$)

- p(**Z**, **X**, $\theta$): Joint distribution 
- **X**: Observed variables
- **Z**: Latent variable
- $\theta$: Governing variable

Goal: Maximize p(__X__, $\theta$) wrt $\theta$


1. init: Choose an initial setting for the param $\theta^{old}$
2. E-step: Evaluate p(**Z**, **X**, $\theta$)
3. M-step: Evaluate $\theta^{new}$ 
	- Given by:  $\theta^{new}$ argmax $Q(\theta,  \theta^{old})$
	- where Q is the expectation as stated before

- repeat 2 & 3



## Exam 2:

Understand Metal-Level EM:

- Convergence
- GMMs & HMMs

- HMMS: Know the general model
	- init: Transition Emission
	- Foward/Backwards (aka D-Step)
	- EM

